---
layout: default
title: Home
---

InterXAI brings together scholars, developers, and critics to reimagine Explainable AI (XAI) through the lens of human-centered design and **intertextual analysis**. We believe explanations aren't just for machines—they’re for people. 

By linking **literary methods** with **technical interpretation**, we aim to reveal the layered meanings in model behavior, decisions, and narratives.

---

## 🚀 What You Can Do with InterXAI

### 📥 [Submit a Case Study]({{ site.baseurl }}/submit/)
Share your applied work or conceptual insights on how humans interact with, interpret, or critique AI explanations.

### 🤝 [Collaborate With Us]({{ site.baseurl }}/collaborate/)
Join interdisciplinary projects blending digital humanities, NLP, and human-centered AI design.

### 🧠 [Explore Case Studies]({{ site.baseurl }}/case-studies/)
Browse existing case studies and see how others are engaging critically with XAI across domains.

### 📝 [Read the Blog]({{ site.baseurl }}/blog/)
Reflective pieces on the tensions, promise, and methods of human-in-the-loop AI understanding.

---

## 🧭 Why Intertextuality?

Modern AI explanations often miss the **human texture**—the narratives, biases, and values that shape understanding. Intertextual critique bridges that gap, inviting diverse voices into the meaning-making process of AI behavior.

By examining **text reuse, metaphors, references, or alternative framings**, we unlock a richer interpretive layer behind machine logic.

---

## 💡 Sample Use Cases

- Analyzing how users interpret LLM-generated answers via user comments
- Reframing algorithmic recommendations through narrative theory
- Highlighting text reuse or inspiration in machine summaries or predictions

---

## 🔗 Stay Connected

We welcome contributions, feedback, and collaborators. [Contact us]({{ site.baseurl }}/about/) or submit a case study to get involved.

---

© 2025 InterXAI Project — All rights reserved.

---
layout: default
title: Home
---

InterXAI brings together scholars, developers, and critics to reimagine Explainable AI (XAI) through the lens of human-centered design and **intertextual analysis**. We believe explanations aren't just for machinesâ€”theyâ€™re for people. 

By linking **literary methods** with **technical interpretation**, we aim to reveal the layered meanings in model behavior, decisions, and narratives.

---

## ğŸš€ What You Can Do with InterXAI

### ğŸ“¥ [Submit a Case Study]({{ site.baseurl }}/submit/)
Share your applied work or conceptual insights on how humans interact with, interpret, or critique AI explanations.

### ğŸ¤ [Collaborate With Us]({{ site.baseurl }}/collaborate/)
Join interdisciplinary projects blending digital humanities, NLP, and human-centered AI design.

### ğŸ§  [Explore Case Studies]({{ site.baseurl }}/case-studies/)
Browse existing case studies and see how others are engaging critically with XAI across domains.

### ğŸ“ [Read the Blog]({{ site.baseurl }}/blog/)
Reflective pieces on the tensions, promise, and methods of human-in-the-loop AI understanding.

---

## ğŸ§­ Why Intertextuality?

Modern AI explanations often miss the **human texture**â€”the narratives, biases, and values that shape understanding. Intertextual critique bridges that gap, inviting diverse voices into the meaning-making process of AI behavior.

By examining **text reuse, metaphors, references, or alternative framings**, we unlock a richer interpretive layer behind machine logic.

---

## ğŸ’¡ Sample Use Cases

- Analyzing how users interpret LLM-generated answers via user comments
- Reframing algorithmic recommendations through narrative theory
- Highlighting text reuse or inspiration in machine summaries or predictions

---

## ğŸ”— Stay Connected

We welcome contributions, feedback, and collaborators. [Contact us]({{ site.baseurl }}/about/) or submit a case study to get involved.

---

Â© 2025 InterXAI Project â€” All rights reserved.
